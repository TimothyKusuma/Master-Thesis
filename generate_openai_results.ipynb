{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to OpenAI API and use the GPT-4V (Vision) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Might want to try multi image inputs'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Might want to try multi image inputs\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Key\n",
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = Path('chatGPT_short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "# List all files in folder_path\n",
    "file_list = [file.name for file in folder_path.iterdir() if file.is_file()]\n",
    "\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# diagram1.yaml, diagram2.yaml, ..., diagram100.\n",
    "all_diagrams = [f\"diagram{i}.yaml\" for i in range(1, 101)]\n",
    "\n",
    "print(len(all_diagrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "filtered_list = [item for item in all_diagrams if item not in file_list]\n",
    "print(len(filtered_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['png/diagram40.png', 'png/diagram41.png', 'png/diagram42.png', 'png/diagram43.png', 'png/diagram44.png', 'png/diagram46.png', 'png/diagram47.png', 'png/diagram49.png', 'png/diagram51.png', 'png/diagram53.png', 'png/diagram54.png', 'png/diagram55.png', 'png/diagram56.png', 'png/diagram57.png', 'png/diagram59.png', 'png/diagram61.png', 'png/diagram62.png', 'png/diagram64.png', 'png/diagram65.png', 'png/diagram67.png', 'png/diagram68.png', 'png/diagram69.png', 'png/diagram70.png', 'png/diagram72.png', 'png/diagram73.png', 'png/diagram74.png', 'png/diagram76.png', 'png/diagram77.png', 'png/diagram78.png', 'png/diagram79.png', 'png/diagram80.png', 'png/diagram81.png', 'png/diagram83.png', 'png/diagram84.png', 'png/diagram85.png', 'png/diagram86.png', 'png/diagram88.png', 'png/diagram89.png', 'png/diagram90.png', 'png/diagram91.png', 'png/diagram92.png', 'png/diagram93.png', 'png/diagram94.png', 'png/diagram95.png', 'png/diagram96.png', 'png/diagram97.png', 'png/diagram98.png']\n"
     ]
    }
   ],
   "source": [
    "# Replace '.yaml' with '.png' in each string\n",
    "updated_list = [f\"png/{item}\".replace('.yaml', '.png') for item in filtered_list]\n",
    "print(updated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if path is valid\n",
    "os.path.isfile(updated_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ScannerError",
     "evalue": "while scanning a quoted scalar\n  in \"<unicode string>\", line 55, column 5:\n      - 'Internal Determinants\n        ^\nfound unexpected end of stream\n  in \"<unicode string>\", line 55, column 27:\n      - 'Internal Determinants\n                              ^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScannerError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\timot\\Documents\\Studium\\Master\\Master-Thesis\\generate_openai_results.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/timot/Documents/Studium/Master/Master-Thesis/generate_openai_results.ipynb#X14sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m final_string \u001b[39m=\u001b[39m pattern\u001b[39m.\u001b[39msub(quote_value, clean_string)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/timot/Documents/Studium/Master/Master-Thesis/generate_openai_results.ipynb#X14sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39m# Parse the YAML string\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/timot/Documents/Studium/Master/Master-Thesis/generate_openai_results.ipynb#X14sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m parsed_data \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39;49msafe_load(final_string)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/timot/Documents/Studium/Master/Master-Thesis/generate_openai_results.ipynb#X14sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39m# Update the figure name field\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/timot/Documents/Studium/Master/Master-Thesis/generate_openai_results.ipynb#X14sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m parsed_data[\u001b[39m'\u001b[39m\u001b[39mfigure\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m figure_name\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\__init__.py:125\u001b[0m, in \u001b[0;36msafe_load\u001b[1;34m(stream)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msafe_load\u001b[39m(stream):\n\u001b[0;32m    118\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39m    Parse the first YAML document in a stream\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m    and produce the corresponding Python object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39m    to be safe for untrusted input.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m load(stream, SafeLoader)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[1;34m(stream, Loader)\u001b[0m\n\u001b[0;32m     79\u001b[0m loader \u001b[39m=\u001b[39m Loader(stream)\n\u001b[0;32m     80\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[39mreturn\u001b[39;00m loader\u001b[39m.\u001b[39;49mget_single_data()\n\u001b[0;32m     82\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     loader\u001b[39m.\u001b[39mdispose()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_single_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     48\u001b[0m     \u001b[39m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_single_node()\n\u001b[0;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m node \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstruct_document(node)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:36\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m document \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(StreamEndEvent):\n\u001b[1;32m---> 36\u001b[0m     document \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_document()\n\u001b[0;32m     38\u001b[0m \u001b[39m# Ensure that the stream contains no more documents.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(StreamEndEvent):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:55\u001b[0m, in \u001b[0;36mComposer.compose_document\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_event()\n\u001b[0;32m     54\u001b[0m \u001b[39m# Compose the root node.\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_node(\u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     57\u001b[0m \u001b[39m# Drop the DOCUMENT-END event.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_event()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m---> 84\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_mapping_node(anchor)\n\u001b[0;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mascend_resolver()\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    129\u001b[0m item_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_node(node, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m \u001b[39m#if item_key in node.value:\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m item_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_node(node, item_key)\n\u001b[0;32m    134\u001b[0m \u001b[39m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[0;32m    135\u001b[0m node\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:82\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     80\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_scalar_node(anchor)\n\u001b[0;32m     81\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(SequenceStartEvent):\n\u001b[1;32m---> 82\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m     84\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_mapping_node(anchor)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:110\u001b[0m, in \u001b[0;36mComposer.compose_sequence_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manchors[anchor] \u001b[39m=\u001b[39m node\n\u001b[0;32m    109\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 110\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_event(SequenceEndEvent):\n\u001b[0;32m    111\u001b[0m     node\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_node(node, index))\n\u001b[0;32m    112\u001b[0m     index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_event \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate:\n\u001b[1;32m---> 98\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate()\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_event \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m choices:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\parser.py:379\u001b[0m, in \u001b[0;36mParser.parse_block_sequence_first_entry\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    377\u001b[0m token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_token()\n\u001b[0;32m    378\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmarks\u001b[39m.\u001b[39mappend(token\u001b[39m.\u001b[39mstart_mark)\n\u001b[1;32m--> 379\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_block_sequence_entry()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\parser.py:384\u001b[0m, in \u001b[0;36mParser.parse_block_sequence_entry\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_token(BlockEntryToken):\n\u001b[0;32m    383\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_token()\n\u001b[1;32m--> 384\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_token(BlockEntryToken, BlockEndToken):\n\u001b[0;32m    385\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_block_sequence_entry)\n\u001b[0;32m    386\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_block_node()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:116\u001b[0m, in \u001b[0;36mScanner.check_token\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_token\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mchoices):\n\u001b[0;32m    114\u001b[0m     \u001b[39m# Check if the next token is one of the given types.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneed_more_tokens():\n\u001b[1;32m--> 116\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetch_more_tokens()\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokens:\n\u001b[0;32m    118\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m choices:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:247\u001b[0m, in \u001b[0;36mScanner.fetch_more_tokens\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39m# Is it a single quoted scalar?\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m ch \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetch_single()\n\u001b[0;32m    249\u001b[0m \u001b[39m# Is it a double quoted scalar?\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39mif\u001b[39;00m ch \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:652\u001b[0m, in \u001b[0;36mScanner.fetch_single\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch_single\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 652\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetch_flow_scalar(style\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:666\u001b[0m, in \u001b[0;36mScanner.fetch_flow_scalar\u001b[1;34m(self, style)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_simple_key \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[39m# Scan and add SCALAR.\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokens\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_flow_scalar(style))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:1151\u001b[0m, in \u001b[0;36mScanner.scan_flow_scalar\u001b[1;34m(self, style)\u001b[0m\n\u001b[0;32m   1149\u001b[0m chunks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_flow_scalar_non_spaces(double, start_mark))\n\u001b[0;32m   1150\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpeek() \u001b[39m!=\u001b[39m quote:\n\u001b[1;32m-> 1151\u001b[0m     chunks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_flow_scalar_spaces(double, start_mark))\n\u001b[0;32m   1152\u001b[0m     chunks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_flow_scalar_non_spaces(double, start_mark))\n\u001b[0;32m   1153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:1238\u001b[0m, in \u001b[0;36mScanner.scan_flow_scalar_spaces\u001b[1;34m(self, double, start_mark)\u001b[0m\n\u001b[0;32m   1236\u001b[0m ch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpeek()\n\u001b[0;32m   1237\u001b[0m \u001b[39mif\u001b[39;00m ch \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\0\u001b[39;00m\u001b[39m'\u001b[39m:\n\u001b[1;32m-> 1238\u001b[0m     \u001b[39mraise\u001b[39;00m ScannerError(\u001b[39m\"\u001b[39m\u001b[39mwhile scanning a quoted scalar\u001b[39m\u001b[39m\"\u001b[39m, start_mark,\n\u001b[0;32m   1239\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfound unexpected end of stream\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_mark())\n\u001b[0;32m   1240\u001b[0m \u001b[39melif\u001b[39;00m ch \u001b[39min\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x85\u001b[39;00m\u001b[39m\\u2028\u001b[39;00m\u001b[39m\\u2029\u001b[39;00m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1241\u001b[0m     line_break \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_line_break()\n",
      "\u001b[1;31mScannerError\u001b[0m: while scanning a quoted scalar\n  in \"<unicode string>\", line 55, column 5:\n      - 'Internal Determinants\n        ^\nfound unexpected end of stream\n  in \"<unicode string>\", line 55, column 27:\n      - 'Internal Determinants\n                              ^"
     ]
    }
   ],
   "source": [
    "# Max number of generated requests to the API\n",
    "limit = 1\n",
    "\n",
    "for i, path in enumerate(updated_list):\n",
    "    if i >= limit:\n",
    "        break\n",
    "    else:\n",
    "        #try:\n",
    "            # Path to your image\n",
    "            image_path = path\n",
    "\n",
    "            # Getting the base64 string\n",
    "            base64_image = encode_image(image_path)\n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {api_key}\"\n",
    "            }\n",
    "\n",
    "            payload = {\n",
    "                \"model\": \"gpt-4-vision-preview\",\n",
    "                \"messages\": [\n",
    "                  {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                      {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"You are an advanced data extraction tool. Analyze the provided research diagrams and extract relevant node data. Format this data in the specified YAML structure. Instructions: 1.\tIdentify different nodes (constructs) in the diagram. Capture every single word and character inside them (including numbers and formulas!). Dotted nodes should be treated the same as solid ones. If nodes contain lists or sub-points, treat them as part of the main node (without '\\n'). Consider the label for groupings as a construct (however, they cannot be used as cause and effect). 2. Capture any additional text present in the diagram that is not part of a node or link (do not classify it as a construct). In the texts section of the YAML file, explicitly enter each piece of additional text with a preceding '-' sign. YAML Output Structure: authors: ''  constructs:    a: NodeLabel1    b: NodeLabel2    ... [and so on for all nodes]  figure: FileNameOfDiagram.png  hypotheses:    1:      cause: a (source node of link)      effect: b (target node of link)      label: ''      name: ''      sign: ''      significance: ''     strength: ''    ... [and so on for all links]  id: ''  name: ''  texts:    - ‘AdditionalText1’    - ‘AdditionalText2’  ... [and so on for all additional texts, **each prefixed by '- '**]  year: ''  Leave all other fields empty for now.\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                          \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                        }\n",
    "                      }\n",
    "                    ]\n",
    "                  }\n",
    "                ],\n",
    "                \"max_tokens\": 300\n",
    "            }\n",
    "\n",
    "            # Send the request to the API\n",
    "            response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "            # Split the string to remove the directory and change the extension\n",
    "            parts = image_path.split('/')\n",
    "            yaml_name = parts[-1].replace('.png', '.yaml')\n",
    "            figure_name = parts[-1]\n",
    "\n",
    "            # access content of response.json()\n",
    "            gpt_vision_answer = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            replaced_string = gpt_vision_answer.replace(\"```yaml\", \"\").replace(\"```\", \"\").replace(\"\\\\n\", \"\\n\").replace(\"\\\\\", \"\").replace(\" \", \" \").replace(\"•\", \"*\")\n",
    "\n",
    "            # The word to search for (cut every line after \"year: \")\n",
    "            search_word_end = \"year:\"\n",
    "\n",
    "            # Find the index of the line containing the word\n",
    "            word_index_end = replaced_string.find(search_word_end)\n",
    "\n",
    "            if word_index_end != -1:\n",
    "                # Find the index of the newline character at the end of this line\n",
    "                newline_index_end = replaced_string.find('\\n', word_index_end)\n",
    "\n",
    "                # If the word is in the last line without a newline\n",
    "                if newline_index_end == -1:\n",
    "                    newline_index_end = len(replaced_string)\n",
    "\n",
    "                # Slice the string up to and including the line with the word\n",
    "                result_string = replaced_string[:newline_index_end]\n",
    "            else:\n",
    "                result_string = replaced_string\n",
    "\n",
    "            # The word to search for (cut every line after \"year: \")\n",
    "            search_word_start = \"year:\"\n",
    "\n",
    "            # Find the index of the line containing the word\n",
    "            word_index_start = result_string.find(search_word_start)\n",
    "\n",
    "            if word_index_start != -1:\n",
    "                # Find the index of the newline character at the end of this line\n",
    "                newline_index_start = result_string.find('\\n', word_index_start)\n",
    "\n",
    "                # If the word is in the last line without a newline\n",
    "                if newline_index_start == -1:\n",
    "                    newline_index_start = len(result_string)\n",
    "\n",
    "                # Slice the string up to and including the line with the word\n",
    "                clean_string = result_string[:newline_index_start]\n",
    "            else:\n",
    "                clean_string = result_string\n",
    "\n",
    "            # Regular expression for adding '' to constructs that has a \":\" \n",
    "            pattern = re.compile(r\"(\\s+[a-zA-Z]):\\s+([^\\n]*:[^\\n]*)\")\n",
    "\n",
    "            # Function to enclose the value in quotes\n",
    "            def quote_value(match):\n",
    "                key = match.group(1)\n",
    "                value = match.group(2)\n",
    "                return f\"{key}: '{value}'\"\n",
    "\n",
    "            # Replace the matched patterns in the string\n",
    "            final_string = pattern.sub(quote_value, clean_string)\n",
    "\n",
    "            # Parse the YAML string\n",
    "            parsed_data = yaml.safe_load(final_string)\n",
    "\n",
    "            # Update the figure name field\n",
    "            parsed_data['figure'] = figure_name\n",
    "            # Specify the file path\n",
    "\n",
    "            print(parsed_data)\n",
    "\n",
    "            yaml_path = f\"chatGPT_short/{yaml_name}\" \n",
    "\n",
    "            # Writing to the file\n",
    "            with open(yaml_path, 'w') as file:\n",
    "                yaml.dump(parsed_data, file)\n",
    "            print(f\"YAML file '{yaml_path}' has been created.\")\n",
    "            \n",
    "        #except Exception as e:\n",
    "        #    print(f\"An error occurred: {e}\")\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "authors: ''\n",
      "constructs:\n",
      "  a: IT activity asset specificity\n",
      "  b: IT department size\n",
      "  c: IT internal organization (profit center)\n",
      "  d: Quasi-Outsourcing\n",
      "  e: Institutional environment (Germany)\n",
      "  f: Sector IT intensity\n",
      "figure: FileNameOfDiagram.png\n",
      "hypotheses:\n",
      "  1:\n",
      "    cause: a\n",
      "    effect: d\n",
      "    label: 'H1 (3.69**)'\n",
      "    name: ''\n",
      "    sign: '+'\n",
      "    significance: '**'\n",
      "    strength: ''\n",
      "  2:\n",
      "    cause: b\n",
      "    effect: d\n",
      "    label: 'H2 (0.95*)'\n",
      "    name: ''\n",
      "    sign: '+'\n",
      "    significance: '*'\n",
      "    strength: ''\n",
      "  3:\n",
      "    cause: c\n",
      "    effect: d\n",
      "    label: 'H3 (3.19**)'\n",
      "    name: ''\n",
      "    sign: '+'\n",
      "    significance: '**'\n",
      "    strength: ''\n",
      "  4:\n",
      "    cause: e\n",
      "    effect: d\n",
      "    label: 'H4 (2.88**)'\n",
      "    name: ''\n",
      "    sign: '+'\n",
      "    significance: '**'\n",
      "    strength: ''\n",
      "  5:\n",
      "    cause: f\n",
      "    effect: d\n",
      "    label: 'H5 (0.04)'\n",
      "    name: ''\n",
      "    sign: ''\n",
      "    significance: ''\n",
      "    strength: ''\n",
      "id: ''\n",
      "name: ''\n",
      "texts:\n",
      "  - 'Internal Determinants\n"
     ]
    },
    {
     "ename": "ScannerError",
     "evalue": "while scanning a quoted scalar\n  in \"<unicode string>\", line 55, column 5:\n      - 'Internal Determinants\n        ^\nfound unexpected end of stream\n  in \"<unicode string>\", line 55, column 27:\n      - 'Internal Determinants\n                              ^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScannerError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\timot\\Documents\\Studium\\Master\\Master-Thesis\\generate_openai_results.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/timot/Documents/Studium/Master/Master-Thesis/generate_openai_results.ipynb#X22sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m final_string \u001b[39m=\u001b[39m pattern\u001b[39m.\u001b[39msub(quote_value, clean_string)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/timot/Documents/Studium/Master/Master-Thesis/generate_openai_results.ipynb#X22sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# Parse the YAML string\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/timot/Documents/Studium/Master/Master-Thesis/generate_openai_results.ipynb#X22sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m parsed_data \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39;49msafe_load(final_string)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/timot/Documents/Studium/Master/Master-Thesis/generate_openai_results.ipynb#X22sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Update the figure name field\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/timot/Documents/Studium/Master/Master-Thesis/generate_openai_results.ipynb#X22sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m parsed_data[\u001b[39m'\u001b[39m\u001b[39mfigure\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m figure_name\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\__init__.py:125\u001b[0m, in \u001b[0;36msafe_load\u001b[1;34m(stream)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msafe_load\u001b[39m(stream):\n\u001b[0;32m    118\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39m    Parse the first YAML document in a stream\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m    and produce the corresponding Python object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39m    to be safe for untrusted input.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m load(stream, SafeLoader)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[1;34m(stream, Loader)\u001b[0m\n\u001b[0;32m     79\u001b[0m loader \u001b[39m=\u001b[39m Loader(stream)\n\u001b[0;32m     80\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[39mreturn\u001b[39;00m loader\u001b[39m.\u001b[39;49mget_single_data()\n\u001b[0;32m     82\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     loader\u001b[39m.\u001b[39mdispose()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_single_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     48\u001b[0m     \u001b[39m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_single_node()\n\u001b[0;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m node \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstruct_document(node)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:36\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m document \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(StreamEndEvent):\n\u001b[1;32m---> 36\u001b[0m     document \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_document()\n\u001b[0;32m     38\u001b[0m \u001b[39m# Ensure that the stream contains no more documents.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(StreamEndEvent):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:55\u001b[0m, in \u001b[0;36mComposer.compose_document\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_event()\n\u001b[0;32m     54\u001b[0m \u001b[39m# Compose the root node.\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_node(\u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     57\u001b[0m \u001b[39m# Drop the DOCUMENT-END event.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_event()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m---> 84\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_mapping_node(anchor)\n\u001b[0;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mascend_resolver()\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    129\u001b[0m item_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_node(node, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m \u001b[39m#if item_key in node.value:\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m item_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_node(node, item_key)\n\u001b[0;32m    134\u001b[0m \u001b[39m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[0;32m    135\u001b[0m node\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:82\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     80\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_scalar_node(anchor)\n\u001b[0;32m     81\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(SequenceStartEvent):\n\u001b[1;32m---> 82\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m     84\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_mapping_node(anchor)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\composer.py:110\u001b[0m, in \u001b[0;36mComposer.compose_sequence_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manchors[anchor] \u001b[39m=\u001b[39m node\n\u001b[0;32m    109\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 110\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_event(SequenceEndEvent):\n\u001b[0;32m    111\u001b[0m     node\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_node(node, index))\n\u001b[0;32m    112\u001b[0m     index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_event \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate:\n\u001b[1;32m---> 98\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate()\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_event \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m choices:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\parser.py:379\u001b[0m, in \u001b[0;36mParser.parse_block_sequence_first_entry\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    377\u001b[0m token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_token()\n\u001b[0;32m    378\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmarks\u001b[39m.\u001b[39mappend(token\u001b[39m.\u001b[39mstart_mark)\n\u001b[1;32m--> 379\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_block_sequence_entry()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\parser.py:384\u001b[0m, in \u001b[0;36mParser.parse_block_sequence_entry\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_token(BlockEntryToken):\n\u001b[0;32m    383\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_token()\n\u001b[1;32m--> 384\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_token(BlockEntryToken, BlockEndToken):\n\u001b[0;32m    385\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_block_sequence_entry)\n\u001b[0;32m    386\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_block_node()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:116\u001b[0m, in \u001b[0;36mScanner.check_token\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_token\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mchoices):\n\u001b[0;32m    114\u001b[0m     \u001b[39m# Check if the next token is one of the given types.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneed_more_tokens():\n\u001b[1;32m--> 116\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetch_more_tokens()\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokens:\n\u001b[0;32m    118\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m choices:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:247\u001b[0m, in \u001b[0;36mScanner.fetch_more_tokens\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39m# Is it a single quoted scalar?\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m ch \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetch_single()\n\u001b[0;32m    249\u001b[0m \u001b[39m# Is it a double quoted scalar?\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39mif\u001b[39;00m ch \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:652\u001b[0m, in \u001b[0;36mScanner.fetch_single\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch_single\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 652\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetch_flow_scalar(style\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:666\u001b[0m, in \u001b[0;36mScanner.fetch_flow_scalar\u001b[1;34m(self, style)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_simple_key \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[39m# Scan and add SCALAR.\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokens\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_flow_scalar(style))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:1151\u001b[0m, in \u001b[0;36mScanner.scan_flow_scalar\u001b[1;34m(self, style)\u001b[0m\n\u001b[0;32m   1149\u001b[0m chunks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_flow_scalar_non_spaces(double, start_mark))\n\u001b[0;32m   1150\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpeek() \u001b[39m!=\u001b[39m quote:\n\u001b[1;32m-> 1151\u001b[0m     chunks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_flow_scalar_spaces(double, start_mark))\n\u001b[0;32m   1152\u001b[0m     chunks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_flow_scalar_non_spaces(double, start_mark))\n\u001b[0;32m   1153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\yaml\\scanner.py:1238\u001b[0m, in \u001b[0;36mScanner.scan_flow_scalar_spaces\u001b[1;34m(self, double, start_mark)\u001b[0m\n\u001b[0;32m   1236\u001b[0m ch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpeek()\n\u001b[0;32m   1237\u001b[0m \u001b[39mif\u001b[39;00m ch \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\0\u001b[39;00m\u001b[39m'\u001b[39m:\n\u001b[1;32m-> 1238\u001b[0m     \u001b[39mraise\u001b[39;00m ScannerError(\u001b[39m\"\u001b[39m\u001b[39mwhile scanning a quoted scalar\u001b[39m\u001b[39m\"\u001b[39m, start_mark,\n\u001b[0;32m   1239\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfound unexpected end of stream\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_mark())\n\u001b[0;32m   1240\u001b[0m \u001b[39melif\u001b[39;00m ch \u001b[39min\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x85\u001b[39;00m\u001b[39m\\u2028\u001b[39;00m\u001b[39m\\u2029\u001b[39;00m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1241\u001b[0m     line_break \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_line_break()\n",
      "\u001b[1;31mScannerError\u001b[0m: while scanning a quoted scalar\n  in \"<unicode string>\", line 55, column 5:\n      - 'Internal Determinants\n        ^\nfound unexpected end of stream\n  in \"<unicode string>\", line 55, column 27:\n      - 'Internal Determinants\n                              ^"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Split the string to remove the directory and change the extension\n",
    "parts = image_path.split('/')\n",
    "yaml_name = parts[-1].replace('.png', '.yaml')\n",
    "figure_name = parts[-1]\n",
    "\n",
    "# access content of response.json()\n",
    "gpt_vision_answer = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "replaced_string = gpt_vision_answer.replace(\"```yaml\", \"\").replace(\"```\", \"\").replace(\"\\\\n\", \"\\n\").replace(\"\\\\\", \"\").replace(\" \", \" \").replace(\"•\", \"*\")\n",
    "print(replaced_string)\n",
    "\n",
    "# The word to search for (cut every line after \"year: \")\n",
    "search_word_end = \"year:\"\n",
    "\n",
    "# Find the index of the line containing the word\n",
    "word_index_end = replaced_string.find(search_word_end)\n",
    "\n",
    "if word_index_end != -1:\n",
    "    # Find the index of the newline character at the end of this line\n",
    "    newline_index_end = replaced_string.find('\\n', word_index_end)\n",
    "\n",
    "    # If the word is in the last line without a newline\n",
    "    if newline_index_end == -1:\n",
    "        newline_index_end = len(replaced_string)\n",
    "\n",
    "    # Slice the string up to and including the line with the word\n",
    "    result_string = replaced_string[:newline_index_end]\n",
    "else:\n",
    "    result_string = replaced_string\n",
    "\n",
    "# The word to search for (cut every line after \"year: \")\n",
    "search_word_start = \"year:\"\n",
    "\n",
    "# Find the index of the line containing the word\n",
    "word_index_start = result_string.find(search_word_start)\n",
    "\n",
    "if word_index_start != -1:\n",
    "    # Find the index of the newline character at the end of this line\n",
    "    newline_index_start = result_string.find('\\n', word_index_start)\n",
    "\n",
    "    # If the word is in the last line without a newline\n",
    "    if newline_index_start == -1:\n",
    "        newline_index_start = len(result_string)\n",
    "\n",
    "    # Slice the string up to and including the line with the word\n",
    "    clean_string = result_string[:newline_index_start]\n",
    "else:\n",
    "    clean_string = result_string\n",
    "\n",
    "# Regular expression for adding '' to constructs that has a \":\" \n",
    "pattern = re.compile(r\"(\\s+[a-zA-Z]):\\s+([^\\n]*:[^\\n]*)\")\n",
    "\n",
    "# Function to enclose the value in quotes\n",
    "def quote_value(match):\n",
    "    key = match.group(1)\n",
    "    value = match.group(2)\n",
    "    return f\"{key}: '{value}'\"\n",
    "\n",
    "# Replace the matched patterns in the string\n",
    "final_string = pattern.sub(quote_value, clean_string)\n",
    "\n",
    "# Parse the YAML string\n",
    "parsed_data = yaml.safe_load(final_string)\n",
    "\n",
    "# Update the figure name field\n",
    "parsed_data['figure'] = figure_name\n",
    "# Specify the file path\n",
    "\n",
    "print(parsed_data)\n",
    "\n",
    "yaml_path = f\"chatGPT_short/{yaml_name}\" \n",
    "\n",
    "# Writing to the file\n",
    "#with open(yaml_path, 'w') as file:\n",
    "#    yaml.dump(parsed_data, file)\n",
    "print(f\"YAML file '{yaml_path}' has been created.\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
